# AI Moderation Express (Backend)

Má»™t dá»‹ch vá»¥ API kiá»ƒm duyá»‡t ná»™i dung (comment/text moderation) xÃ¢y dá»±ng báº±ng **Express + TypeScript + Bun**, há»— trá»£ **Hugging Face** vÃ  **OpenAI**.  
Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»… má»Ÿ rá»™ng, tá»‘i Æ°u cho tiáº¿ng Viá»‡t vá»›i bá»™ luáº­t `VN_RULES`.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh
- Gá»i **Hugging Face Inference API** hoáº·c **OpenAI Moderation API** Ä‘á»ƒ phÃ¢n loáº¡i ná»™i dung.
- Há»— trá»£ **Ä‘a ngÃ´n ngá»¯**, tá»‘i Æ°u cho **tiáº¿ng Viá»‡t** báº±ng:
  - Chuáº©n hoÃ¡ Unicode + bá» dáº¥u.
  - Chuyá»ƒn Ä‘á»•i leetspeak (vd: `l0n` â†’ `lon`).
  - Lá»›p luáº­t `VN_RULES` Ä‘á»ƒ báº¯t tá»« khÃ³a tá»¥c/insult phá»• biáº¿n.
- Cho phÃ©p cáº¥u hÃ¬nh ngÆ°á»¡ng (`HF_THRESHOLD`) vÃ  fallback top-1.
- Bá»™ nhá»› Ä‘á»‡m (cache) káº¿t quáº£ Ä‘á»ƒ giáº£m sá»‘ láº§n gá»i API.
- Debug mode Ä‘á»ƒ xem dá»¯ liá»‡u thÃ´ tá»« model.
- API RESTful Ä‘Æ¡n giáº£n, dá»… tÃ­ch há»£p vá»›i frontend.

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c
```

src/
config/env.ts                # Load vÃ  parse biáº¿n mÃ´i trÆ°á»ng
server.ts                    # Khá»Ÿi cháº¡y Express server
routes/moderation.routes.ts  # Äá»‹nh nghÄ©a route /comments/moderate
controllers/                 # Xá»­ lÃ½ request/response
services/
moderation/
huggingface.service.ts   # Gá»i HF API + fine-tune BE
openai.service.ts        # Gá»i OpenAI API
reason-map.ts            # Map label â†’ taxonomy chung
vn-rules.ts              # Luáº­t tá»« khÃ³a tiáº¿ng Viá»‡t
text-normalize.ts          # HÃ m chuáº©n hoÃ¡ vÄƒn báº£n
types/                       # TypeScript types & type guards
.env.example                   # Máº«u cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

````

---

## âš™ï¸ CÃ i Ä‘áº·t

### 1. Clone repo
```bash
git clone https://github.com/your-username/ai-moderation-express.git
cd ai-moderation-express
````

### 2. CÃ i dependencies

```bash
bun install
```

### 3. Táº¡o file `.env`

Dá»±a trÃªn `.env.example`:

```env
PORT=3000

# Provider: huggingface hoáº·c openai
PROVIDER=huggingface

# Hugging Face
HF_API_KEY=hf_xxx
HF_MODEL=unitary/toxic-bert
HF_THRESHOLD=0.5
HF_TOP1_FALLBACK=0.7

# Luáº­t tiáº¿ng Viá»‡t
VN_RULES_ENABLED=true
VN_RULES_STRICT=false

# Cache (ms)
CACHE_TTL_MS=60000

# Debug mode
PROVIDER_DEBUG=true

# OpenAI (náº¿u dÃ¹ng)
# OPENAI_API_KEY=sk-...
```

---

## â–¶ï¸ Cháº¡y server

### Dev mode (hot reload)

```bash
bun dev
```

### Production

```bash
bun start
```

Máº·c Ä‘á»‹nh API sáº½ cháº¡y á»Ÿ:
`http://localhost:3000`

---

## Tá»•ng quan há»‡ thá»‘ng (kiáº¿n trÃºc)

```mermaid
flowchart LR
  subgraph Client
    FE[Frontend App / Postman]
  end

  subgraph BE[Express Backend]
    CTR[Controller\n/moderation.controller.ts]
    HF[HuggingFace Service\nhuggingface.service.ts]
    OA[OpenAI Service\nopenai.service.ts]
    VN[VN Rules\nvn-rules.ts]
    TN[Text Normalize\ntext-normalize.ts]
    RM[Reason Map\nreason-map.ts]
    CACHE[(In-memory Cache)]
    ENV[[env.ts]]
  end

  subgraph External
    HFI[Hugging Face Inference API]
    OAI[OpenAI Moderation API]
  end

  FE -->|POST /comments/moderate| CTR
  CTR --> TN
  CTR -->|provider=huggingface| HF
  CTR -->|provider=openai| OA
  HF <-->|get/set| CACHE
  HF -->|options.wait_for_model=true| HFI
  OA --> OAI
  HF --> RM
  OA --> RM
  CTR --> VN
  CTR -->|JSON decision| FE
  ENV --- CTR
  ENV --- HF
  ENV --- OA
```

## ğŸ“¡ API Endpoints

### **POST** `/comments/moderate`

Kiá»ƒm duyá»‡t má»™t Ä‘oáº¡n vÄƒn báº£n.

#### Request body

```json
{
  "text": "tháº±ng ngu"
}
```

```json
{
  "allowed": false,
  "reasons": ["harassment"],
  "debug": {
    "model": "unitary/toxic-bert",
    "threshold": 0.5,
    "raw": [...]
  }
}
```

* `allowed`: `true` náº¿u vÄƒn báº£n Ä‘Æ°á»£c cháº¥p nháº­n, `false` náº¿u bá»‹ cháº·n.
* `reasons`: LÃ½ do bá»‹ cháº·n (taxonomy chung).
* `debug`: ThÃ´ng tin chi tiáº¿t (báº­t qua `PROVIDER_DEBUG=true`).

---

#### Request â€“ Response

```mermaid
sequenceDiagram
  autonumber
  participant FE as Frontend / Client
  participant API as Express Controller
  participant TN as Text Normalize
  participant HF as HF Service
  participant VN as VN Rules
  participant RM as Reason Map
  participant HFI as HF Inference API
  participant C as Cache

  FE->>API: POST /comments/moderate { text }
  API->>TN: normalizeForModeration(text)
  TN-->>API: normalizedText
  API->>HF: moderateWithHF(normalizedText)
  HF->>C: check cache
  alt cache hit
    C-->>HF: decision
    HF-->>API: decision
  else cache miss
    HF->>HFI: {inputs, options:{wait_for_model:true}}
    HFI-->>HF: raw scores (labels, scores[])
    HF->>RM: normalizeHFLabels(labels)
    RM-->>HF: reasons[]
    HF-->>API: { allowed, reasons, debug? }
    HF->>C: set cache(decision)
  end
  API->>VN: violatesVietnameseRules(originalText)
  alt VN rule matched
    VN-->>API: true
    API->>API: reasons.push('harassment')
  else
    VN-->>API: false
  end
  API-->>FE: { allowed, reasons, debug? }
````

---

## ğŸ›  Fine-tune logic á»Ÿ BE

* **Chuáº©n hoÃ¡ text** trÆ°á»›c khi gá»­i model (`normalizeForModeration`).
* **VN\_RULES** override káº¿t quáº£ model náº¿u phÃ¡t hiá»‡n tá»« khÃ³a vi pháº¡m tiáº¿ng Viá»‡t.
* **NgÆ°á»¡ng linh hoáº¡t**: Fallback láº¥y top-1 náº¿u vÆ°á»£t má»™t tá»‰ lá»‡ so vá»›i threshold (`HF_TOP1_FALLBACK`).
* **Cache** giÃºp giáº£m sá»‘ láº§n gá»i API vá»›i text trÃ¹ng láº·p.

---

## ğŸ”„ Chuyá»ƒn Ä‘á»•i giá»¯a Hugging Face & OpenAI

Chá»‰ cáº§n Ä‘á»•i biáº¿n mÃ´i trÆ°á»ng `PROVIDER`:

```env
PROVIDER=openai
OPENAI_API_KEY=sk-...
```

> Code sáº½ tá»± Ä‘á»™ng chá»n service tÆ°Æ¡ng á»©ng.

---

## ğŸ§ª Test nhanh vá»›i cURL

```bash
curl -X POST http://localhost:3000/comments/moderate \
  -H "Content-Type: application/json" \
  -d '{"text":"tháº±ng chÃ³ ngu"}'
```

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£ - Nguyá»…n Huá»³nh Sang

Pet project phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p vÃ  tÃ­ch há»£p AI vÃ o há»‡ thá»‘ng kiá»ƒm duyá»‡t ná»™i dung.

